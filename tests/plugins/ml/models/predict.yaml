$schema: ../../../../json_schemas/test_story.schema.yaml

description: Test the prediction of new data.
distributions:
  excluded:
    - amazon-managed
    - amazon-serverless
warnings:
  multiple-paths-detected: false
prologues:
  - path: /_cluster/settings
    method: PUT
    request:
      payload:
        persistent:
          plugins.ml_commons.only_run_on_ml_node: false
          plugins.ml_commons.model_access_control_enabled: true
          plugins.ml_commons.native_memory_threshold: 99
  - path: /_plugins/_ml/model_groups/_register
    id: create_model_group
    method: POST
    request:
      payload:
        name: NLP_Group
        description: Model group for NLP models.
    output:
      test_model_group_id: payload.model_group_id
  - path: /_plugins/_ml/models/_register
    id: register_model
    method: POST
    request:
      payload:
        name: huggingface/sentence-transformers/msmarco-distilbert-base-tas-b
        version: 1.0.1
        model_format: TORCH_SCRIPT
    output:
      task_id: payload.task_id
epilogues:
  - path: /_plugins/_ml/models/{model_id}/_undeploy
    method: POST
    parameters:
      model_id: ${get_completed_register_model_task.model_id}
    status: [200, 404]
  - path: /_plugins/_ml/models/{model_id}
    parameters:
      model_id: ${get_completed_register_model_task.model_id}
    method: DELETE
    status: [200, 404]
  - path: /_plugins/_ml/model_groups/{model_group_id}
    method: DELETE
    status: [200, 404]
    parameters:
      model_group_id: ${create_model_group.test_model_group_id}
chapters:
  - synopsis: Wait to get completed task.
    id: get_completed_register_model_task
    path: /_plugins/_ml/tasks/{task_id}
    method: GET
    parameters:
      task_id: ${register_model.task_id}
    response:
      status: 200
      payload:
        state: COMPLETED
    output:
      model_id: payload.model_id
    retry:
      count: 3
      wait: 10000
  - synopsis: Deploy a model.
    id: deploy_model
    path: /_plugins/_ml/models/{model_id}/_deploy
    method: POST
    parameters:
      model_id: ${get_completed_register_model_task.model_id}
    output:
      task_id: payload.task_id
    response:
      status: 200
  - synopsis: Wait to get completed task.
    id: get_completed_deploy_model_task
    path: /_plugins/_ml/tasks/{task_id}
    method: GET
    parameters:
      task_id: ${deploy_model.task_id}
    response:
      status: 200
      payload:
        state: COMPLETED
    output:
      model_id: payload.model_id
    retry:
      count: 3
      wait: 10000
  - synopsis: Predict new data.
    id: predict_data
    path: /_plugins/_ml/models/{model_id}/_predict
    method: POST
    parameters:
      model_id: ${get_completed_register_model_task.model_id}
    request:
      payload:
        query_text: today is sunny
        text_docs:
          - how are you
          - it is winter
          - today is july fifth
          - today is sunny
    response:
      status: 200
      payload:
        inference_results:
          - output:
            - data:
              - 101
    output:
      prediction_results: payload.inference_results[0].output[0].data
  - synopsis: Undeploy a model.
    path: /_plugins/_ml/models/{model_id}/_undeploy
    method: POST
    parameters:
      model_id: ${get_completed_register_model_task.model_id}
    response:
      status: 200